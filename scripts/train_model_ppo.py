import os
import pandas as pd
import warnings
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from env import TradeEnv  # ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶π‡¶ì ‡¶Ø‡ßá env.py ‡¶§‡ßá ‡¶Ü‡¶™‡¶°‡ßá‡¶ü‡ßá‡¶° TradeEnv ‡¶Ü‡¶õ‡ßá

# ‚ö†Ô∏è Warning ‡¶Ö‡¶´
warnings.simplefilter(action='ignore', category=FutureWarning)

# --- Helper Functions ---
def load_csv_safe(path):
    try:
        if os.path.exists(path):
            df = pd.read_csv(path)
            print(f"‚úÖ Loaded: {path} ({len(df)} rows)")
            return df
        else:
            print(f"‚ö†Ô∏è File not found: {path}")
    except Exception as e:
        print(f"‚ùå Failed to load {path}: {e}")
    return pd.DataFrame()

# --- Load Datasets ---
main_df = load_csv_safe('./csv/mongodb.csv')

# ‚úÖ ‡¶®‡¶§‡ßÅ‡¶® CSV ‡¶´‡¶æ‡¶á‡¶≤‡¶ó‡ßÅ‡¶≤‡ßã ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®
gape_df = load_csv_safe("./csv/gape.csv")
gapebuy_df = load_csv_safe("./csv/gape_buy.csv")
shortbuy_df = load_csv_safe("./csv/short_buy.csv")
rsi_diver_df = load_csv_safe("./csv/rsi_diver.csv")
rsi_diver_retest_df = load_csv_safe("./csv/rsi_diver_retest.csv")

# --- Create Environment ---
try:
    env = TradeEnv(
        maindf=main_df,
        gape_path="./csv/gape.csv",
        gapebuy_path="./csv/gape_buy.csv",
        shortbuy_path="./csv/short_buy.csv",
        rsi_diver_path="./csv/rsi_diver.csv",
        rsi_diver_retest_path="./csv/rsi_diver_retest.csv"
    )
    print("‚úÖ Environment initialized")
except Exception as e:
    print(f"‚ùå Failed to initialize environment: {e}")
    exit()

# --- Wrap Environment ---
env = DummyVecEnv([lambda: env])

# --- Create PPO Model ---
try:
    model = PPO(
        policy="MlpPolicy",
        env=env,
        verbose=1,
        learning_rate=3e-4,
        n_steps=2048,
        batch_size=64,
        gamma=0.99,
        gae_lambda=0.95,
        ent_coef=0.01,
        clip_range=0.2,
        n_epochs=10,
        device='cpu'
        #tensorboard_log="./ppo_tensorboard/"
    )
    print("‚úÖ PPO model created")

except Exception as e:
    print(f"‚ùå Failed to create PPO model: {e}")
    exit()

# --- Train PPO Model ---
try:
    print("üöÄ Training the PPO model...")
    model.learn(total_timesteps=200_000)
    print("‚úÖ PPO Training complete")

except Exception as e:
    print(f"‚ùå Training failed: {e}")
    exit()

# --- Save PPO Model ---
try:
    save_path = './csv/ppo_retrained'
    model.save(save_path)
    print(f"‚úÖ PPO model saved at: {save_path}")
except Exception as e:
    print(f"‚ùå Failed to save PPO model: {e}")