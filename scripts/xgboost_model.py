# xgboost_model.py - ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü‡ßá‡¶° ‡¶≠‡¶æ‡¶∞‡ßç‡¶∏‡¶®
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, classification_report
from imblearn.over_sampling import SMOTE
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

class XGBoostTradingModel:
    def __init__(self, n_estimators=1000, max_depth=5, learning_rate=0.01):
        self.model = None
        self.scaler = StandardScaler()
        self.feature_importance = None
        self.params = {
            'n_estimators': n_estimators,
            'max_depth': max_depth,
            'learning_rate': learning_rate,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'random_state': 42,
            'early_stopping_rounds': 50,  # ‚úÖ ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶∏‡¶∞‡¶ø‡ßü‡ßá ‡¶Ü‡¶®‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá
            'eval_metric': 'mlogloss'  # ‡¶Æ‡¶æ‡¶≤‡ßç‡¶ü‡¶ø-‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶â‡¶™‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§
        }
        
    def prepare_data(self, market_data, trade_data):
        """
        ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï‡ßá‡¶ü ‡¶è‡¶¨‡¶Ç ‡¶ü‡ßç‡¶∞‡ßá‡¶° ‡¶°‡¶æ‡¶ü‡¶æ ‡¶™‡ßç‡¶∞‡¶ø‡¶™‡ßá‡ßü‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá
        """
        print("üìä ‡¶≤‡ßã‡¶°‡¶ø‡¶Ç ‡¶è‡¶¨‡¶Ç ‡¶°‡¶æ‡¶ü‡¶æ ‡¶™‡ßç‡¶∞‡¶ø‡¶™‡ßá‡ßü‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá...")
        print(f"   ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï‡ßá‡¶ü ‡¶°‡¶æ‡¶ü‡¶æ ‡¶Ü‡¶ï‡¶æ‡¶∞: {market_data.shape}")
        print(f"   ‡¶ü‡ßç‡¶∞‡ßá‡¶° ‡¶°‡¶æ‡¶ü‡¶æ ‡¶Ü‡¶ï‡¶æ‡¶∞: {trade_data.shape}")
        
        # 1. ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶§‡ßà‡¶∞‡¶ø
        market_data['returns'] = market_data['close'].pct_change()
        market_data['volatility'] = market_data['returns'].rolling(5).std()
        market_data['volume_ma'] = market_data['volume'].rolling(5).mean()
        
        # 2. ‡¶°‡¶æ‡¶ü‡¶æ ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ú
        merged_data = pd.merge(market_data, trade_data, 
                              on=['symbol', 'date'], 
                              how='left')
        
        # 3. ‡¶ü‡¶æ‡¶∞‡ßç‡¶ó‡ßá‡¶ü ‡¶≠‡ßç‡¶Ø‡¶æ‡¶∞‡¶ø‡ßü‡ßá‡¶¨‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø
        merged_data['signal'] = merged_data['buy'].notna().astype(int)
        merged_data['signal_type'] = 0  # ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü: ‡¶®‡ßã ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤
        
        # ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ 1: ‡¶∞‡ßá‡¶ó‡ßÅ‡¶≤‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤
        buy_mask = merged_data['buy'].notna()
        merged_data.loc[buy_mask, 'signal_type'] = 1
        
        # ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ 2: ‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶Ç ‡¶¨‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ (‡¶Ø‡¶¶‡¶ø RRR1 > 2.0)
        strong_buy_mask = buy_mask & (merged_data['RRR'] > 2.0)
        merged_data.loc[strong_buy_mask, 'signal_type'] = 2
        
        print(f"   ‡¶¨‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶ó‡ßá‡¶õ‡ßá: {merged_data['signal'].sum()} out of {len(merged_data)} samples ({merged_data['signal'].sum()/len(merged_data)*100:.2f}%)")
        print(f"   ‡¶ü‡¶æ‡¶∞‡ßç‡¶ó‡ßá‡¶ü ‡¶°‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø‡¶¨‡¶ø‡¶â‡¶∂‡¶®: {dict(Counter(merged_data['signal_type']))}")
        
        # 4. ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶∏‡¶ø‡¶≤‡ßá‡¶ï‡¶∂‡¶®
        features = [
            'open', 'high', 'low', 'close', 'volume',
            'returns', 'volatility', 'volume_ma',
            'marketCap', 'rsi', 'macd', 'macd_hist',
            'atr', 'Hammer', 'BullishEngulfing', 
            'MorningStar', 'Doji', 'diff'
        ]
        
        # ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶∏‡ßá‡¶á ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞‡¶ó‡ßÅ‡¶≤‡ßã ‡¶®‡¶ø‡¶® ‡¶Ø‡ßá‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ü‡¶õ‡ßá
        available_features = [f for f in features if f in merged_data.columns]
        print(f"   ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá {len(available_features)} ‡¶ü‡¶ø ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞")
        
        # 5. NaN ‡¶≠‡ßç‡¶Ø‡¶æ‡¶≤‡ßÅ ‡¶π‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡¶≤‡¶ø‡¶Ç
        original_len = len(merged_data)
        merged_data = merged_data.dropna(subset=available_features + ['signal_type'])
        dropped_rows = original_len - len(merged_data)
        print(f"   NaN ‡¶≠‡ßç‡¶Ø‡¶æ‡¶≤‡ßÅ ‡¶∏‡¶π {dropped_rows} ‡¶ü‡¶ø ‡¶∏‡¶æ‡¶∞‡¶ø ‡¶°‡ßç‡¶∞‡¶™ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá")
        print(f"   ‡¶´‡¶æ‡¶á‡¶®‡¶æ‡¶≤ ‡¶°‡¶æ‡¶ü‡¶æ ‡¶Ü‡¶ï‡¶æ‡¶∞: {merged_data.shape}")
        
        return merged_data, available_features
    
    def train(self, market_data, trade_data):
        """
        XGBoost ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶® ‡¶ï‡¶∞‡ßá
        """
        # 1. ‡¶°‡¶æ‡¶ü‡¶æ ‡¶™‡ßç‡¶∞‡¶ø‡¶™‡ßá‡ßü‡¶æ‡¶∞
        data, features = self.prepare_data(market_data, trade_data)
        
        # 2. ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶è‡¶¨‡¶Ç ‡¶ü‡¶æ‡¶∞‡ßç‡¶ó‡ßá‡¶ü ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ ‡¶ï‡¶∞‡¶æ
        X = data[features]
        y_binary = data['signal']  # ‡¶¨‡¶æ‡¶á‡¶®‡¶æ‡¶∞‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶ø‡¶ï‡ßá‡¶∂‡¶®
        y_multi = data['signal_type']  # ‡¶Æ‡¶æ‡¶≤‡ßç‡¶ü‡¶ø-‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶ø‡¶ï‡ßá‡¶∂‡¶®
        
        # 3. ‡¶ü‡ßç‡¶∞‡ßá‡¶®-‡¶ü‡ßá‡¶∏‡ßç‡¶ü ‡¶∏‡ßç‡¶™‡ßç‡¶≤‡¶ø‡¶ü
        X_train, X_test, y_bin_train, y_bin_test, y_multi_train, y_multi_test = train_test_split(
            X, y_binary, y_multi, test_size=0.3, random_state=42, stratify=y_multi
        )
        
        print(f"\nü§ñ XGBoost ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∂‡ßÅ‡¶∞‡ßÅ...")
        print(f"   ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∏‡ßç‡¶Ø‡¶æ‡¶Æ‡ßç‡¶™‡¶≤: {X_train.shape[0]}")
        print(f"   ‡¶ü‡ßá‡¶∏‡ßç‡¶ü‡¶ø‡¶Ç ‡¶∏‡ßç‡¶Ø‡¶æ‡¶Æ‡ßç‡¶™‡¶≤: {X_test.shape[0]}")
        print(f"   ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶°‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø‡¶¨‡¶ø‡¶â‡¶∂‡¶® - ‡¶¨‡¶æ‡¶á‡¶®‡¶æ‡¶∞‡¶ø: {dict(Counter(y_bin_train))}")
        print(f"   ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶°‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø‡¶¨‡¶ø‡¶â‡¶∂‡¶® - ‡¶Æ‡¶æ‡¶≤‡ßç‡¶ü‡¶ø: {dict(Counter(y_multi_train))}")
        
        # 4. SMOTE ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶≤‡¶æ‡¶á ‡¶ï‡¶∞‡¶æ (‡¶∂‡ßç‡¶∞‡ßá‡¶£‡ßÄ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶≤‡ßá‡¶®‡ßç‡¶∏‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø)
        print("   ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶≤‡ßá‡¶®‡ßç‡¶∏‡¶ø‡¶Ç‡ßü‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø SMOTE ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶≤‡¶æ‡¶á ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá...")
        smote = SMOTE(random_state=42)
        X_train_balanced, y_bin_train_balanced = smote.fit_resample(X_train, y_bin_train)
        print(f"   SMOTE ‡¶™‡¶∞‡ßá: {dict(Counter(y_bin_train_balanced))}")
        
        # 5. ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶ì‡ßü‡ßá‡¶ü ‡¶ï‡ßç‡¶Ø‡¶æ‡¶≤‡¶ï‡ßÅ‡¶≤‡ßá‡¶ü
        scale_pos_weight = len(y_bin_train_balanced[y_bin_train_balanced == 0]) / len(y_bin_train_balanced[y_bin_train_balanced == 1])
        print(f"   ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶ì‡ßü‡ßá‡¶ü (scale_pos_weight): {scale_pos_weight:.2f}")
        
        # 6. XGBoost ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø
        print("   ‡¶¨‡¶æ‡¶á‡¶®‡¶æ‡¶∞‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶ø‡¶ï‡ßá‡¶∂‡¶® ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç...")
        
        # ‚úÖ early_stopping_rounds ‡¶è‡¶ñ‡¶® ‡¶ï‡¶®‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶æ‡¶ï‡ßç‡¶ü‡¶∞‡ßá
        self.model = xgb.XGBClassifier(
            n_estimators=self.params['n_estimators'],
            max_depth=self.params['max_depth'],
            learning_rate=self.params['learning_rate'],
            subsample=self.params['subsample'],
            colsample_bytree=self.params['colsample_bytree'],
            random_state=self.params['random_state'],
            early_stopping_rounds=self.params['early_stopping_rounds'],  # ‚úÖ ‡¶è‡¶ñ‡¶æ‡¶®‡ßá
            eval_metric=self.params['eval_metric'],
            scale_pos_weight=scale_pos_weight,
            use_label_encoder=False
        )
        
        # 7. ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç
        # ‚úÖ eval_set ‡¶è‡¶ñ‡¶® .fit() ‡¶Æ‡ßá‡¶•‡¶°‡ßá
        self.model.fit(
            X_train_balanced,
            y_bin_train_balanced,
            eval_set=[(X_test, y_bin_test)],  # ‚úÖ ‡¶è‡¶ñ‡¶æ‡¶®‡ßá
            verbose=False
        )
        
        # 8. ‡¶™‡¶æ‡¶∞‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶∏ ‡¶á‡¶≠‡ßç‡¶Ø‡¶æ‡¶≤‡ßÅ‡ßü‡ßá‡¶∂‡¶®
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_bin_test, y_pred)
        f1 = f1_score(y_bin_test, y_pred)
        
        print(f"\n‚úÖ ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£!")
        print(f"   ‡¶è‡¶ï‡ßÅ‡¶∞‡ßá‡¶∏‡¶ø: {accuracy:.4f}")
        print(f"   F1 ‡¶∏‡ßç‡¶ï‡ßã‡¶∞: {f1:.4f}")
        print(f"\nüìä ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶ø‡¶ï‡ßá‡¶∂‡¶® ‡¶∞‡¶ø‡¶™‡ßã‡¶∞‡ßç‡¶ü:")
        print(classification_report(y_bin_test, y_pred, target_names=['No Signal', 'Buy Signal']))
        
        # 9. ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶á‡¶Æ‡ßç‡¶™‡¶∞‡¶ü‡ßá‡¶®‡ßç‡¶∏
        self.feature_importance = pd.DataFrame({
            'feature': features,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print(f"\nüèÜ Top 5 ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞:")
        for i, row in self.feature_importance.head().iterrows():
            print(f"   {row['feature']}: {row['importance']:.4f}")
        
        return accuracy, f1
    
    def predict(self, market_data, trade_data):
        """
        ‡¶®‡¶§‡ßÅ‡¶® ‡¶°‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶® ‡¶ï‡¶∞‡ßá
        """
        data, features = self.prepare_data(market_data, trade_data)
        
        if self.model is None:
            raise ValueError("‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶® ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡¶®‡¶ø‡•§ ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá .train() ‡¶Æ‡ßá‡¶•‡¶° ‡¶ï‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®")
        
        # ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶®
        predictions = self.model.predict(data[features])
        probabilities = self.model.predict_proba(data[features])
        
        # ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü ‡¶°‡¶æ‡¶ü‡¶æ‡¶´‡ßç‡¶∞‡ßá‡¶Æ
        result_df = data[['symbol', 'date', 'open', 'high', 'low', 'close', 'volume']].copy()
        result_df['predicted_signal'] = predictions
        result_df['signal_probability'] = probabilities[:, 1]  # ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ 1-‡¶è‡¶∞ ‡¶™‡ßç‡¶∞‡ßã‡¶¨‡¶æ‡¶¨‡¶ø‡¶≤‡¶ø‡¶ü‡¶ø
        
        # ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶´‡¶ø‡¶≤‡ßç‡¶ü‡¶æ‡¶∞ (‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶¨‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤)
        buy_signals = result_df[result_df['predicted_signal'] == 1].copy()
        
        # ‡¶∞‡¶ø‡¶∏‡ßç‡¶ï ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶ú‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶™‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶Æ‡¶ø‡¶ü‡¶æ‡¶∞ ‡¶Ø‡ßã‡¶ó
        buy_signals['position_size'] = 100  # ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü
        buy_signals['stop_loss'] = buy_signals['close'] * 0.95  # 5% ‡¶∏‡ßç‡¶ü‡¶™ ‡¶≤‡¶∏
        buy_signals['take_profit'] = buy_signals['close'] * 1.10  # 10% ‡¶ü‡ßá‡¶ï ‡¶™‡ßç‡¶∞‡¶´‡¶ø‡¶ü
        buy_signals['risk_reward_ratio'] = (buy_signals['take_profit'] - buy_signals['close']) / (buy_signals['close'] - buy_signals['stop_loss'])
        
        return result_df, buy_signals
    
    def save_model(self, path='./models/xgboost_model.json'):
        """
        ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡ßá
        """
        import os
        os.makedirs(os.path.dirname(path), exist_ok=True)
        self.model.save_model(path)
        print(f"‚úÖ ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá: {path}")
    
    def load_model(self, path='./models/xgboost_model.json'):
        """
        ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßá
        """
        self.model = xgb.XGBClassifier()
        self.model.load_model(path)
        print(f"‚úÖ ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá: {path}")

def main():
    """
    ‡¶Æ‡ßá‡¶á‡¶® ‡¶è‡¶ï‡ßç‡¶∏‡¶ø‡¶ï‡¶ø‡¶â‡¶∂‡¶® ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®
    """
    print("=" * 70)
    print("XGBOOST ‡¶ü‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶Ç ‡¶Æ‡¶°‡ßá‡¶≤ - ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶°‡¶≠‡¶æ‡¶®‡ßç‡¶∏‡¶° ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç")
    print("=" * 70)
    
    # 1. ‡¶°‡¶æ‡¶ü‡¶æ ‡¶≤‡ßã‡¶°
    print("\nüì• ‡¶°‡¶æ‡¶ü‡¶æ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá...")
    
    try:
        market_data = pd.read_csv("./csv/mongodb.csv")
        trade_data = pd.read_csv("./csv/trade_stock.csv")
        
        # ‡¶§‡¶æ‡¶∞‡¶ø‡¶ñ ‡¶ï‡¶®‡¶≠‡¶æ‡¶∞‡ßç‡¶ü
        market_data['date'] = pd.to_datetime(market_data['date'])
        trade_data['date'] = pd.to_datetime(trade_data['date'])
        
    except FileNotFoundError as e:
        print(f"‚ùå ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü‡¶®‡¶ø: {e}")
        return
    except Exception as e:
        print(f"‚ùå ‡¶°‡¶æ‡¶ü‡¶æ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ: {e}")
        return
    
    # 2. XGBoost ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø ‡¶è‡¶¨‡¶Ç ‡¶ü‡ßç‡¶∞‡ßá‡¶®
    model = XGBoostTradingModel(
        n_estimators=500,  # ‡¶ï‡¶Æ‡¶ø‡ßü‡ßá ‡¶Ü‡¶®‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç‡ßü‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø
        max_depth=4,
        learning_rate=0.05
    )
    
    try:
        accuracy, f1 = model.train(market_data, trade_data)
        
        # 3. ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡ßá‡¶≠
        model.save_model('./models/xgboost_trading_model.json')
        
        # 4. ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶® ‡¶§‡ßà‡¶∞‡¶ø
        print("\nüîÆ ‡¶®‡¶§‡ßÅ‡¶® ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá...")
        all_predictions, buy_signals = model.predict(market_data, trade_data)
        
        # 5. ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü ‡¶∏‡ßá‡¶≠
        buy_signals.to_csv("./csv/xgboost_predictions.csv", index=False)
        print(f"‚úÖ {len(buy_signals)} ‡¶ü‡¶ø ‡¶¨‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ CSV ‡¶§‡ßá ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá: ./csv/xgboost_predictions.csv")
        
        # 6. ‡¶∏‡¶æ‡¶Æ‡¶æ‡¶∞‡¶ø ‡¶°‡¶ø‡¶∏‡¶™‡ßç‡¶≤‡ßá
        print(f"\nüìà ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∏‡¶æ‡¶Æ‡¶æ‡¶∞‡¶ø:")
        print(f"   ‚Ä¢ ‡¶´‡¶æ‡¶á‡¶®‡¶æ‡¶≤ ‡¶è‡¶ï‡ßÅ‡¶∞‡ßá‡¶∏‡¶ø: {accuracy:.2%}")
        print(f"   ‚Ä¢ F1 ‡¶∏‡ßç‡¶ï‡ßã‡¶∞: {f1:.4f}")
        print(f"   ‚Ä¢ ‡¶ü‡¶™ ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞: {model.feature_importance.iloc[0]['feature']}")
        print(f"   ‚Ä¢ ‡¶ü‡ßã‡¶ü‡¶æ‡¶≤ ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤: {len(buy_signals)}")
        
        if len(buy_signals) > 0:
            print(f"\nüéØ ‡¶∂‡ßÄ‡¶∞‡ßç‡¶∑ 3 ‡¶ü‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶Ç ‡¶∏‡ßÅ‡¶Ø‡ßã‡¶ó:")
            top_signals = buy_signals.sort_values('signal_probability', ascending=False).head(3)
            for idx, row in top_signals.iterrows():
                print(f"   {row['symbol']} - {row['date'].date()}")
                print(f"     ‡¶™‡ßç‡¶∞‡¶æ‡¶á‡¶∏: {row['close']:.2f}, ‡¶™‡ßç‡¶∞‡ßã‡¶¨‡¶æ‡¶¨‡¶ø‡¶≤‡¶ø‡¶ü‡¶ø: {row['signal_probability']:.2%}")
                print(f"     R/R ‡¶∞‡ßá‡¶∂‡¶ø‡¶ì: {row['risk_reward_ratio']:.2f}")
        
    except Exception as e:
        print(f"‚ùå ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç/‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶®‡ßá ‡¶è‡¶∞‡¶∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
