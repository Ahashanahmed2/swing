# xgboost_model.py - ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü‡ßá‡¶° ‡¶≠‡¶æ‡¶∞‡ßç‡¶∏‡¶®
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, classification_report
from imblearn.over_sampling import SMOTE
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

class XGBoostTradingModel:
    def __init__(self, n_estimators=1000, max_depth=5, learning_rate=0.01):
        self.model = None
        self.scaler = StandardScaler()
        self.feature_importance = None
        self.params = {
            'n_estimators': n_estimators,
            'max_depth': max_depth,
            'learning_rate': learning_rate,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'random_state': 42,
            'early_stopping_rounds': 50,
            'eval_metric': 'logloss',  # ‚úÖ ‡¶¨‡¶æ‡¶á‡¶®‡¶æ‡¶∞‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶ø‡¶ï‡ßá‡¶∂‡¶®‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø
            'objective': 'binary:logistic'  # ‚úÖ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
        }
        
    def prepare_data(self, market_data, trade_data):
    """
    Symbol-specific ‡¶°‡¶æ‡¶ü‡¶æ ‡¶™‡ßç‡¶∞‡¶ø‡¶™‡ßá‡ßü‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá
    """
    symbol = market_data['symbol'].iloc[0] if len(market_data) > 0 else 'UNKNOWN'
    
    # 1. ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶§‡ßà‡¶∞‡¶ø
    market_data = market_data.copy()
    
    # ‡¶™‡ßç‡¶∞‡¶æ‡¶á‡¶∏-‡¶¨‡ßá‡¶∏‡¶° ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞
    market_data['returns'] = market_data['close'].pct_change()
    market_data['returns_ma'] = market_data['returns'].rolling(5).mean()
    market_data['volatility'] = market_data['returns'].rolling(5).std()
    
    # ‡¶≠‡¶≤‡¶ø‡¶â‡¶Æ ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞
    market_data['volume_ma'] = market_data['volume'].rolling(5).mean()
    market_data['volume_ratio'] = market_data['volume'] / market_data['volume_ma']
    
    # ‡¶™‡ßç‡¶∞‡¶æ‡¶á‡¶∏ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡ßç‡¶° ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞
    market_data['price_ma_5'] = market_data['close'].rolling(5).mean()
    market_data['price_ma_10'] = market_data['close'].rolling(10).mean()
    market_data['price_ma_ratio'] = market_data['price_ma_5'] / market_data['price_ma_10']
    
    # 2. ‡¶°‡¶æ‡¶ü‡¶æ ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ú
    merged_data = pd.merge(
        market_data, 
        trade_data, 
        on=['symbol', 'date'], 
        how='left',
        suffixes=('', '_trade')
    )
    
    # 3. ‡¶ü‡¶æ‡¶∞‡ßç‡¶ó‡ßá‡¶ü ‡¶≠‡ßç‡¶Ø‡¶æ‡¶∞‡¶ø‡ßü‡ßá‡¶¨‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø
    merged_data['signal'] = merged_data['buy'].notna().astype(int)
    
    # RRR-based ‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶Ç ‡¶¨‡¶æ‡¶á ‡¶°‡¶ø‡¶ü‡ßá‡¶ï‡¶∂‡¶®
    merged_data['signal_type'] = 0  # ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü: ‡¶®‡ßã ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤
    
    if 'buy' in merged_data.columns and merged_data['buy'].notna().any():
        buy_mask = merged_data['buy'].notna()
        merged_data.loc[buy_mask, 'signal_type'] = 1  # ‡¶∏‡¶¨ buy ‡¶ï‡ßá ‡¶∞‡ßá‡¶ó‡ßÅ‡¶≤‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶á
        
        # ‡¶Ø‡¶¶‡¶ø RRR ‡¶•‡¶æ‡¶ï‡ßá ‡¶§‡¶¨‡ßá ‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶Ç ‡¶¨‡¶æ‡¶á ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡¶ø‡¶§
        if 'RRR' in merged_data.columns:
            # Symbol-specific ‡¶•‡ßç‡¶∞‡ßá‡¶∂‡¶π‡ßã‡¶≤‡ßç‡¶°
            valid_rrr = merged_data.loc[buy_mask, 'RRR']
            if valid_rrr.notna().any():
                median_rrr = valid_rrr.median()
                strong_buy_threshold = max(median_rrr * 1.2, 1.5)  # ‡¶Æ‡¶ø‡¶°‡¶ø‡ßü‡¶æ‡¶® ‡¶•‡ßá‡¶ï‡ßá 20% ‡¶¨‡ßá‡¶∂‡¶ø
                
                strong_buy_mask = buy_mask & (merged_data['RRR'] > strong_buy_threshold)
                merged_data.loc[strong_buy_mask, 'signal_type'] = 2
    else:
        # ‡¶Ø‡¶¶‡¶ø ‡¶ï‡ßã‡¶® buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá
        merged_data['signal'] = 0
        merged_data['signal_type'] = 0
    
    # 4. ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶∏‡¶ø‡¶≤‡ßá‡¶ï‡¶∂‡¶®
    base_features = [
        'open', 'high', 'low', 'close', 'volume',
        'returns', 'returns_ma', 'volatility',
        'volume_ma', 'volume_ratio',
        'price_ma_5', 'price_ma_10', 'price_ma_ratio'
    ]
    
    # ‡¶ü‡ßá‡¶ï‡¶®‡¶ø‡¶ï‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶á‡¶®‡ßç‡¶°‡¶ø‡¶ï‡ßá‡¶ü‡¶∞‡¶∏ ‡¶Ø‡ßã‡¶ó (‡¶Ø‡¶¶‡¶ø ‡¶•‡¶æ‡¶ï‡ßá)
    tech_indicators = ['rsi', 'macd', 'macd_hist', 'atr', 'marketCap']
    for indicator in tech_indicators:
        if indicator in merged_data.columns:
            base_features.append(indicator)
    
    # ‡¶ü‡ßç‡¶∞‡ßá‡¶°-‡¶¨‡ßá‡¶∏‡¶° ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ (‡¶Ø‡¶¶‡¶ø ‡¶•‡¶æ‡¶ï‡ßá)
    trade_features = ['diff', 'RRR', 'position_size']
    for feature in trade_features:
        if feature in merged_data.columns:
            base_features.append(feature)
    
    # 5. ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶∏‡ßá‡¶á ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞‡¶ó‡ßÅ‡¶≤‡ßã ‡¶®‡¶ø‡¶® ‡¶Ø‡ßá‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ü‡¶õ‡ßá
    available_features = [f for f in base_features if f in merged_data.columns]
    
    # 6. NaN ‡¶≠‡ßç‡¶Ø‡¶æ‡¶≤‡ßÅ ‡¶π‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡¶≤‡¶ø‡¶Ç
    original_len = len(merged_data)
    valid_mask = merged_data[available_features].notna().all(axis=1)
    merged_data = merged_data[valid_mask].copy()
    dropped_rows = original_len - len(merged_data)
    
    return merged_data, available_features

def train(self, market_data, trade_data):
    """
    Symbol-specific XGBoost ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶® ‡¶ï‡¶∞‡ßá (SMOTE ‡¶õ‡¶æ‡ßú‡¶æ)
    """
    symbol = market_data['symbol'].iloc[0] if len(market_data) > 0 else 'UNKNOWN'
    print(f"   üîÑ {symbol} - ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∂‡ßÅ‡¶∞‡ßÅ...")

    # 1. ‡¶°‡¶æ‡¶ü‡¶æ ‡¶™‡ßç‡¶∞‡¶ø‡¶™‡ßá‡ßü‡¶æ‡¶∞
    data, features = self.prepare_data(market_data, trade_data)

    if len(data) < 30:  # ‡¶ï‡¶Æ‡¶™‡¶ï‡ßç‡¶∑‡ßá 30 ‡¶¶‡¶ø‡¶®‡ßá‡¶∞ ‡¶°‡¶æ‡¶ü‡¶æ ‡¶ö‡¶æ‡¶á
        print(f"   ‚ö†Ô∏è ‡¶™‡¶∞‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶§ ‡¶°‡¶æ‡¶ü‡¶æ ‡¶®‡ßá‡¶á: {len(data)} days")
        return 0.0, 0.0

    # 2. ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶è‡¶¨‡¶Ç ‡¶ü‡¶æ‡¶∞‡ßç‡¶ó‡ßá‡¶ü ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ ‡¶ï‡¶∞‡¶æ
    X = data[features]
    y_binary = data['signal']  # ‡¶¨‡¶æ‡¶á‡¶®‡¶æ‡¶∞‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶ø‡¶ï‡ßá‡¶∂‡¶®

    # 3. ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶°‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø‡¶¨‡¶ø‡¶â‡¶∂‡¶® ‡¶ö‡ßá‡¶ï
    class_counts = Counter(y_binary)
    total_samples = len(y_binary)

    print(f"   üìä ‡¶°‡¶æ‡¶ü‡¶æ ‡¶Ü‡¶ï‡¶æ‡¶∞: {X.shape}")
    print(f"   üéØ ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶°‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø‡¶¨‡¶ø‡¶â‡¶∂‡¶®: {dict(class_counts)}")
    print(f"   Buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤: {class_counts.get(1, 0)} / {total_samples} ({class_counts.get(1, 0)/total_samples*100:.1f}%)")

    # 4. ‡¶Ø‡¶¶‡¶ø buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶ñ‡ßÅ‡¶¨ ‡¶ï‡¶Æ ‡¶•‡¶æ‡¶ï‡ßá
    if class_counts.get(1, 0) < 2:
        print(f"   ‚ö†Ô∏è ‡¶ñ‡ßÅ‡¶¨ ‡¶ï‡¶Æ buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ({class_counts.get(1, 0)}), ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∏‡¶Æ‡ßç‡¶≠‡¶¨ ‡¶®‡ßü")
        return 0.0, 0.0

    # 5. ‡¶ü‡ßç‡¶∞‡ßá‡¶®-‡¶ü‡ßá‡¶∏‡ßç‡¶ü ‡¶∏‡ßç‡¶™‡ßç‡¶≤‡¶ø‡¶ü (‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø‡¶á stratified)
    try:
        # ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡ßá y_binary-‡¶§‡ßá ‡¶ï‡¶Æ‡¶™‡¶ï‡ßç‡¶∑‡ßá 2‡¶ü‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶Ü‡¶õ‡ßá
        unique_classes = np.unique(y_binary)
        if len(unique_classes) < 2:
            print(f"   ‚ùå ‡¶∂‡ßÅ‡¶ß‡ßÅ 1‡¶ü‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶ó‡ßá‡¶õ‡ßá: {unique_classes}")
            print(f"   ‚úÖ ‡¶ï‡ßÉ‡¶§‡ßç‡¶∞‡¶ø‡¶Æ buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá...")
            
            # ‡¶Ø‡¶¶‡¶ø ‡¶∏‡¶¨ 0 ‡¶•‡¶æ‡¶ï‡ßá, 1‡¶ü‡¶ø ‡¶ï‡ßÉ‡¶§‡ßç‡¶∞‡¶ø‡¶Æ buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
            if len(data) > 10:
                # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ 10‡¶ü‡¶ø ‡¶°‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá 1‡¶ü‡¶ø buy ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
                y_binary.iloc[0] = 1
                print(f"   ‚úÖ 1‡¶ü‡¶ø ‡¶ï‡ßÉ‡¶§‡ßç‡¶∞‡¶ø‡¶Æ buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá")
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_binary, 
            test_size=0.3, 
            random_state=42,
            stratify=y_binary
        )
    except Exception as e:
        print(f"   ‚ö†Ô∏è Stratified split ‡¶∏‡¶Æ‡ßç‡¶≠‡¶¨ ‡¶®‡ßü: {str(e)[:50]}")
        # Regular split ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_binary, 
            test_size=0.3, 
            random_state=42
        )

    # 6. ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶ì‡ßü‡ßá‡¶ü ‡¶ï‡ßç‡¶Ø‡¶æ‡¶≤‡¶ï‡ßÅ‡¶≤‡ßá‡¶ü
    n_class_0 = np.sum(y_train == 0)
    n_class_1 = np.sum(y_train == 1)

    if n_class_1 == 0:
        print(f"   ‚ö†Ô∏è ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∏‡ßá‡¶ü‡ßá ‡¶ï‡ßã‡¶® buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶®‡ßá‡¶á")
        # ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ï‡ßÉ‡¶§‡ßç‡¶∞‡¶ø‡¶Æ buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
        if len(X_train) > 0:
            y_train.iloc[0] = 1
            n_class_1 = 1
            print(f"   ‚úÖ 1‡¶ü‡¶ø ‡¶ï‡ßÉ‡¶§‡ßç‡¶∞‡¶ø‡¶Æ buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá")

    scale_pos_weight = n_class_0 / max(n_class_1, 1)  # Zero division ‡¶è‡ßú‡¶æ‡¶®‡ßã
    print(f"   ‚öñÔ∏è Class Weight: {scale_pos_weight:.2f}")
    print(f"   üèãÔ∏è ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∏‡ßç‡¶Ø‡¶æ‡¶Æ‡ßç‡¶™‡¶≤: {X_train.shape[0]}")
    print(f"   üß™ ‡¶ü‡ßá‡¶∏‡ßç‡¶ü‡¶ø‡¶Ç ‡¶∏‡ßç‡¶Ø‡¶æ‡¶Æ‡ßç‡¶™‡¶≤: {X_test.shape[0]}")

    # 7. XGBoost ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø (SMOTE ‡¶õ‡¶æ‡ßú‡¶æ)
    print("   ü§ñ ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∂‡ßÅ‡¶∞‡ßÅ...")

    try:
        self.model = xgb.XGBClassifier(
            n_estimators=self.params['n_estimators'],
            max_depth=self.params['max_depth'],
            learning_rate=self.params['learning_rate'],
            subsample=self.params['subsample'],
            colsample_bytree=self.params['colsample_bytree'],
            random_state=self.params['random_state'],
            early_stopping_rounds=self.params['early_stopping_rounds'],
            eval_metric=self.params['eval_metric'],
            objective=self.params['objective'],
            scale_pos_weight=scale_pos_weight,
            use_label_encoder=False,
            verbosity=0
        )

        # 8. ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç (SMOTE ‡¶¨‡ßç‡¶Ø‡¶æ‡¶≤‡ßá‡¶®‡ßç‡¶∏‡¶° ‡¶°‡¶æ‡¶ü‡¶æ ‡¶õ‡¶æ‡ßú‡¶æ‡¶á)
        self.model.fit(
            X_train,
            y_train,  # ‚úÖ Original ‡¶°‡¶æ‡¶ü‡¶æ, SMOTE ‡¶¨‡ßç‡¶Ø‡¶æ‡¶≤‡ßá‡¶®‡ßç‡¶∏‡¶° ‡¶®‡ßü
            eval_set=[(X_test, y_test)],
            verbose=False
        )

        # 9. ‡¶™‡¶æ‡¶∞‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶∏ ‡¶á‡¶≠‡ßç‡¶Ø‡¶æ‡¶≤‡ßÅ‡ßü‡ßá‡¶∂‡¶®
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, zero_division=0)

        print(f"   ‚úÖ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£!")
        print(f"   üéØ Accuracy: {accuracy:.4f}")
        print(f"   üìà F1 Score: {f1:.4f}")

        if y_test.sum() > 0:  # ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶Ø‡¶¶‡¶ø ‡¶ü‡ßá‡¶∏‡ßç‡¶ü‡ßá buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶•‡¶æ‡¶ï‡ßá
            print(f"\n   üìä Classification Report:")
            print(classification_report(y_test, y_pred, target_names=['No Signal', 'Buy Signal']))

        # 10. ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶á‡¶Æ‡ßç‡¶™‡¶∞‡¶ü‡ßá‡¶®‡ßç‡¶∏
        if hasattr(self.model, 'feature_importances_'):
            self.feature_importance = pd.DataFrame({
                'feature': features,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False)

            print(f"   üèÜ Top 3 Important Features:")
            for i, row in self.feature_importance.head(3).iterrows():
                print(f"      {row['feature']}: {row['importance']:.4f}")

        return accuracy, f1

    except Exception as e:
        print(f"   ‚ùå ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶è‡¶∞‡¶∞: {str(e)[:100]}")
        import traceback
        traceback.print_exc()
        return 0.0, 0.0

def predict(self, market_data, trade_data=None):
    """
    ‡¶®‡¶§‡ßÅ‡¶® ‡¶°‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶® ‡¶ï‡¶∞‡ßá
    """
    if self.model is None:
        raise ValueError("‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶® ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡¶®‡¶ø‡•§ ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá .train() ‡¶Æ‡ßá‡¶•‡¶° ‡¶ï‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®")
    
    # ‡¶Ø‡¶¶‡¶ø trade_data ‡¶®‡¶æ ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶π‡ßü, ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï‡ßá‡¶ü ‡¶°‡¶æ‡¶ü‡¶æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞
    if trade_data is None:
        trade_data = pd.DataFrame(columns=['symbol', 'date', 'buy', 'RRR'])
    
    # ‡¶°‡¶æ‡¶ü‡¶æ ‡¶™‡ßç‡¶∞‡¶ø‡¶™‡ßá‡ßü‡¶æ‡¶∞
    data, features = self.prepare_data(market_data, trade_data)
    
    if len(data) == 0:
        return pd.DataFrame(), pd.DataFrame()
    
    # ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶®
    predictions = self.model.predict(data[features])
    probabilities = self.model.predict_proba(data[features])
    
    # ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü ‡¶°‡¶æ‡¶ü‡¶æ‡¶´‡ßç‡¶∞‡ßá‡¶Æ
    result_df = data[['symbol', 'date', 'open', 'high', 'low', 'close', 'volume']].copy()
    result_df['predicted_signal'] = predictions
    result_df['signal_probability'] = probabilities[:, 1]  # ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ 1-‡¶è‡¶∞ ‡¶™‡ßç‡¶∞‡ßã‡¶¨‡¶æ‡¶¨‡¶ø‡¶≤‡¶ø‡¶ü‡¶ø
    
    # ‡¶Æ‡ßá‡¶ü‡ßç‡¶∞‡¶ø‡¶ï‡ßç‡¶∏ ‡¶Ø‡ßã‡¶ó
    result_df['returns'] = result_df['close'].pct_change()
    result_df['volatility'] = result_df['returns'].rolling(5).std()
    
    # ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶´‡¶ø‡¶≤‡ßç‡¶ü‡¶æ‡¶∞ (‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶¨‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤)
    buy_signals = result_df[result_df['predicted_signal'] == 1].copy()
    
    # ‡¶∞‡¶ø‡¶∏‡ßç‡¶ï ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶ú‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶™‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶Æ‡¶ø‡¶ü‡¶æ‡¶∞ ‡¶Ø‡ßã‡¶ó
    if len(buy_signals) > 0:
        # ATR-‡¶¨‡ßá‡¶∏‡¶° ‡¶∏‡ßç‡¶ü‡¶™ ‡¶≤‡¶∏ (‡¶Ø‡¶¶‡¶ø atr ‡¶•‡¶æ‡¶ï‡ßá)
        if 'atr' in data.columns:
            buy_signals = buy_signals.merge(
                data[['date', 'atr']], 
                on='date', 
                how='left'
            )
            buy_signals['stop_loss'] = buy_signals['close'] - (buy_signals['atr'] * 1.5)
            buy_signals['take_profit'] = buy_signals['close'] + (buy_signals['atr'] * 3)
        else:
            buy_signals['stop_loss'] = buy_signals['close'] * 0.95
            buy_signals['take_profit'] = buy_signals['close'] * 1.10
        
        buy_signals['risk_reward_ratio'] = (buy_signals['take_profit'] - buy_signals['close']) / (buy_signals['close'] - buy_signals['stop_loss'])
        buy_signals['position_size'] = 100  # ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü
        
        # ‡¶ï‡¶®‡¶´‡¶ø‡¶°‡ßá‡¶®‡ßç‡¶∏ ‡¶≤‡ßá‡¶≠‡ßá‡¶≤ ‡¶¨‡ßá‡¶∏‡¶° ‡¶∏‡¶∞‡ßç‡¶ü‡¶ø‡¶Ç
        buy_signals['confidence'] = buy_signals['signal_probability'] * buy_signals['risk_reward_ratio']
    
    return result_df, buy_signals

def save_model(self, path):
    """
    ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡ßá
    """
    os.makedirs(os.path.dirname(path), exist_ok=True)
    self.model.save_model(path)

def load_model(self, path):
    """
    ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßá
    """
    self.model = xgb.XGBClassifier()
    self.model.load_model(path)

def main():
    """
    ‡¶Æ‡ßá‡¶á‡¶® ‡¶è‡¶ï‡ßç‡¶∏‡¶ø‡¶ï‡¶ø‡¶â‡¶∂‡¶® ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®
    """
    print("=" * 70)
    print("XGBOOST ‡¶ü‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶Ç ‡¶Æ‡¶°‡ßá‡¶≤ - ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶°‡¶≠‡¶æ‡¶®‡ßç‡¶∏‡¶° ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç")
    print("=" * 70)
    
   # ‡¶°‡¶ø‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶∞‡¶ø ‡¶§‡ßà‡¶∞‡¶ø
os.makedirs('./models', exist_ok=True)
os.makedirs('./csv', exist_ok=True)

# 1. ‡¶°‡¶æ‡¶ü‡¶æ ‡¶≤‡ßã‡¶°
print("\nüì• ‡¶°‡¶æ‡¶ü‡¶æ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá...")

try:
    market_data = pd.read_csv("./csv/mongodb.csv")
    trade_data = pd.read_csv("./csv/trade_stock.csv")
    
    # ‡¶§‡¶æ‡¶∞‡¶ø‡¶ñ ‡¶ï‡¶®‡¶≠‡¶æ‡¶∞‡ßç‡¶ü
    market_data['date'] = pd.to_datetime(market_data['date'])
    trade_data['date'] = pd.to_datetime(trade_data['date'])
    
    print(f"   ‚úÖ ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï‡ßá‡¶ü ‡¶°‡¶æ‡¶ü‡¶æ: {market_data.shape}")
    print(f"   ‚úÖ ‡¶ü‡ßç‡¶∞‡ßá‡¶° ‡¶°‡¶æ‡¶ü‡¶æ: {trade_data.shape}")
    
except FileNotFoundError as e:
    print(f"‚ùå ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü‡¶®‡¶ø: {e}")
    print(f"   ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶• ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®: ./csv/mongodb.csv ‡¶è‡¶¨‡¶Ç ./csv/trade_stock.csv")
    return
except Exception as e:
    print(f"‚ùå ‡¶°‡¶æ‡¶ü‡¶æ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ: {e}")
    return

# 2. Symbol ‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶§‡ßà‡¶∞‡¶ø
market_symbols = set(market_data['symbol'].unique())
trade_symbols = set(trade_data['symbol'].unique())
common_symbols = sorted(market_symbols.intersection(trade_symbols))

print(f"\nüìä Symbol ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£:")
print(f"   üìà ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï‡ßá‡¶ü symbols: {len(market_symbols)}")
print(f"   üí∞ ‡¶ü‡ßç‡¶∞‡ßá‡¶° symbols: {len(trade_symbols)}")
print(f"   ‚úÖ ‡¶ï‡¶Æ‡¶® symbols: {len(common_symbols)}")

if len(common_symbols) == 0:
    print("‚ùå ‡¶ï‡ßã‡¶® ‡¶ï‡¶Æ‡¶® symbol ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü‡¶®‡¶ø!")
    print("   ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï‡ßá‡¶ü ‡¶è‡¶¨‡¶Ç ‡¶ü‡ßç‡¶∞‡ßá‡¶° ‡¶°‡¶æ‡¶ü‡¶æ‡ßü ‡¶Æ‡¶ø‡¶≤‡¶®‡¶∏‡¶á symbol ‡¶®‡ßá‡¶á")
    return

print(f"\nüéØ ‡¶™‡ßç‡¶∞‡¶•‡¶Æ 10 ‡¶ü‡¶ø symbol: {common_symbols[:10]}")

# 3. ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø symbol-‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç
results = []
all_buy_signals = []

print(f"\nüöÄ {len(common_symbols)} ‡¶ü‡¶ø symbol-‡¶è‡¶∞ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∂‡ßÅ‡¶∞‡ßÅ...")
print("=" * 70)

for i, symbol in enumerate(common_symbols, 1):
    print(f"\n[{i}/{len(common_symbols)}] üîÑ Processing: {symbol}")
    print("-" * 50)
    
    # Symbol-specific ‡¶°‡¶æ‡¶ü‡¶æ ‡¶´‡¶ø‡¶≤‡ßç‡¶ü‡¶æ‡¶∞
    symbol_market = market_data[market_data['symbol'] == symbol].copy()
    symbol_trade = trade_data[trade_data['symbol'] == symbol].copy()
    
    # ‡¶°‡¶æ‡¶ü‡¶æ ‡¶ö‡ßá‡¶ï
    if len(symbol_market) < 50:
        print(f"   ‚ö†Ô∏è ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï‡ßá‡¶ü ‡¶°‡¶æ‡¶ü‡¶æ ‡¶ï‡¶Æ: {len(symbol_market)} days (minimum 50 required)")
        continue
        
    if len(symbol_trade) == 0:
        print(f"   ‚ö†Ô∏è ‡¶ï‡ßã‡¶® ‡¶ü‡ßç‡¶∞‡ßá‡¶° ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶®‡ßá‡¶á")
        continue
    
    print(f"   üìà ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï‡ßá‡¶ü ‡¶°‡¶æ‡¶ü‡¶æ: {symbol_market.shape[0]} days")
    print(f"   üéØ ‡¶ü‡ßç‡¶∞‡ßá‡¶° ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤: {len(symbol_trade)} signals")
    
    # 4. ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø ‡¶è‡¶¨‡¶Ç ‡¶ü‡ßç‡¶∞‡ßá‡¶®
    model = XGBoostTradingModel(
        n_estimators=150,
        max_depth=4,
        learning_rate=0.05
    )
    
    try:
        accuracy, f1 = model.train(symbol_market, symbol_trade)
        
        # ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£
        result_entry = {
            'symbol': symbol,
            'accuracy': accuracy,
            'f1_score': f1,
            'market_days': len(symbol_market),
            'trade_signals': len(symbol_trade),
            'signal_percentage': len(symbol_trade) / len(symbol_market) * 100,
            'success': accuracy > 0
        }
        
        results.append(result_entry)
        
        if accuracy > 0.5:  # ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶Æ‡¶°‡ßá‡¶≤‡¶ó‡ßÅ‡¶≤‡ßã ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡ßç‡¶ü ‡¶ï‡¶∞‡¶¨‡ßá
            # 5. ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶® ‡¶§‡ßà‡¶∞‡¶ø
            print(f"   üîÆ ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá...")
            all_preds, buy_signals = model.predict(symbol_market)
            
            if len(buy_signals) > 0:
                all_buy_signals.append(buy_signals)
                print(f"   ‚úÖ {len(buy_signals)} ‡¶ü‡¶ø ‡¶¨‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶ó‡ßá‡¶õ‡ßá")
                
                # ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡ßá‡¶≠
                model_path = f'./models/xgboost_{symbol.replace("/", "_")}.json'
                model.save_model(model_path)
                
                # Symbol-specific ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶® ‡¶∏‡ßá‡¶≠
                buy_signals_path = f'./csv/predictions_{symbol.replace("/", "_")}.csv'
                buy_signals.to_csv(buy_signals_path, index=False)
            
        else:
            print(f"   ‚ö†Ô∏è Low accuracy, skipping predictions")
            
    except Exception as e:
        print(f"   ‚ùå ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•: {str(e)[:80]}")
        results.append({
            'symbol': symbol,
            'accuracy': 0.0,
            'f1_score': 0.0,
            'market_days': len(symbol_market),
            'trade_signals': len(symbol_trade),
            'signal_percentage': len(symbol_trade) / len(symbol_market) * 100,
            'success': False,
            'error': str(e)[:80]
        })

# 6. ‡¶´‡¶æ‡¶á‡¶®‡¶æ‡¶≤ ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü‡¶∏ ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏
print(f"\n{'='*70}")
print("üìä FINAL TRAINING SUMMARY")
print(f"{'='*70}")

if results:
    results_df = pd.DataFrame(results)
    
    # ‡¶∏‡¶´‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç
    successful = results_df[results_df['success'] == True]
    failed = results_df[results_df['success'] == False]
    
    print(f"‚úÖ ‡¶∏‡¶´‡¶≤‡¶≠‡¶æ‡¶¨‡ßá ‡¶ü‡ßç‡¶∞‡ßá‡¶® ‡¶π‡ßü‡ßá‡¶õ‡ßá: {len(successful)} symbols")
    print(f"‚ùå ‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶• ‡¶π‡ßü‡ßá‡¶õ‡ßá: {len(failed)} symbols")
    
    if len(successful) > 0:
        print(f"\nüèÜ Top 5 Performing Symbols:")
        top_symbols = successful.sort_values('f1_score', ascending=False).head()
        for idx, row in top_symbols.iterrows():
            print(f"   {row['symbol']}:")
            print(f"     Accuracy: {row['accuracy']:.3f}, F1: {row['f1_score']:.3f}")
            print(f"     Signals: {row['trade_signals']}/{row['market_days']} ({row['signal_percentage']:.1f}%)")
    
    # ‡¶∏‡¶Æ‡¶∏‡ßç‡¶§ ‡¶¨‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶è‡¶ï‡¶§‡ßç‡¶∞‡¶ø‡¶§
    if all_buy_signals:
        final_signals = pd.concat(all_buy_signals, ignore_index=True)
        
        # ‡¶ï‡¶®‡¶´‡¶ø‡¶°‡ßá‡¶®‡ßç‡¶∏ ‡¶¨‡ßá‡¶∏‡¶° ‡¶∏‡¶∞‡ßç‡¶ü
        if 'confidence' in final_signals.columns:
            final_signals = final_signals.sort_values('confidence', ascending=False)
        
        # CSV ‡¶§‡ßá ‡¶∏‡ßá‡¶≠
        final_signals.to_csv("./csv/xgboost_all_predictions.csv", index=False)
        
        print(f"\nüìÅ PREDICTIONS SUMMARY:")
        print(f"   ‡¶Æ‡ßã‡¶ü ‡¶¨‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤: {len(final_signals)}")
        print(f"   ‡¶∏‡ßá‡¶≠ ‡¶π‡ßü‡ßá‡¶õ‡ßá: ./csv/xgboost_all_predictions.csv")
        
        # ‡¶∂‡ßÄ‡¶∞‡ßç‡¶∑ 5 ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶°‡¶ø‡¶∏‡¶™‡ßç‡¶≤‡ßá
        if len(final_signals) > 0:
            print(f"\nüéØ TOP 5 TRADING OPPORTUNITIES:")
            top_5 = final_signals.head(5)
            for idx, row in top_5.iterrows():
                confidence = row.get('confidence', row.get('signal_probability', 0))
                print(f"   {row['symbol']} - {row['date'].date()}")
                print(f"     Price: {row['close']:.2f}, Signal: {row['signal_probability']:.1%}")
                if 'risk_reward_ratio' in row:
                    print(f"     R/R: {row['risk_reward_ratio']:.2f}, Confidence: {confidence:.3f}")
    
    # ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü‡¶∏ CSV ‡¶§‡ßá ‡¶∏‡ßá‡¶≠
    results_df.to_csv("./csv/xgboost_training_results.csv", index=False)
    print(f"\nüìÑ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü‡¶∏: ./csv/xgboost_training_results.csv")
    
    # ‡¶∏‡¶æ‡¶Æ‡¶æ‡¶∞‡¶ø ‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶ü‡¶∏
    print(f"\nüìà OVERALL STATISTICS:")
    print(f"   ‡¶ó‡ßú Accuracy: {results_df['accuracy'].mean():.3f}")
    print(f"   ‡¶ó‡ßú F1 Score: {results_df['f1_score'].mean():.3f}")
    print(f"   ‡¶∏‡¶∞‡ßç‡¶¨‡ßã‡¶ö‡ßç‡¶ö Accuracy: {results_df['accuracy'].max():.3f}")
    print(f"   ‡¶Æ‡ßã‡¶ü ‡¶Æ‡¶°‡ßá‡¶≤: {len(results_df)}")
    
else:
    print("‚ùå ‡¶ï‡ßã‡¶® symbol ‡¶∏‡¶´‡¶≤‡¶≠‡¶æ‡¶¨‡ßá ‡¶ü‡ßç‡¶∞‡ßá‡¶® ‡¶π‡ßü‡¶®‡¶ø")
    print("   ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡ßç‡¶Ø ‡¶ï‡¶æ‡¶∞‡¶£:")
    print("   1. ‡¶ñ‡ßÅ‡¶¨ ‡¶ï‡¶Æ buy ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤")
    print("   2. ‡¶°‡¶æ‡¶ü‡¶æ quality issue")
    print("   3. Feature engineering ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ")

print(f"\n{'='*70}")
print("‚úÖ PROGRAM COMPLETED")
print(f"{'='*70}")

if name="main:
  main()